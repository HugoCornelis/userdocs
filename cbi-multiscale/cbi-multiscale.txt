Definitions:
http://www.cs.cmu.edu/~dst/NIPS/nips08-workshop/Mike_Arnold.pdf
Multiple sub-models at differing abstractions and time-scales can be combined into a single heterogeneous multi-scale model using both synchronous and asynchronous approaches.

http://math.la.asu.edu/~cans/tutorials.html
PSICS, http://www.psics.org
PSICS models the behavior of neurons taking account of the stochastic nature of ion channel gating and the detailed positions of the channels themselves. PSICS is intended to be complementary to existing tools. With its focus on kinetic scheme channel models, stochastic behavior, and detailed geometry, it lives in the space between stochastic diffusion models of small sections of neurons (MCell, STEPS) and deterministic whole cell models (Neuron, Genesis).

http://www.biomedcentral.com/1471-2202/10/S1/P54
Multiscale modeling and interoperability in MOOSE

http://www.imagwiki.nibib.nih.gov/mediawiki/index.php?title=Computational_Neuroscience_Working_Group
TITLE: What do we mean by multi-scale modeling: Report from CNS 2011 workshop in Stockholm.
SUMMARY - Drs. Bower and Rybak will report on a workshop on multiscale modeling in computational neuroscience held as part of the 20th annual International Computational Neuroscience meeting (CNS*11) held in Stockholm, Sweden in July, 2011. The workshop considered challenges facing multi-scale modeling in computational neuroscience and produced a schema intended to describe and organize multi-scale modeling development efforts. This schema will be used as a basis for considering the current state of multi-scale modeling in computational neuroscience, as well as areas for future development.

http://www.imagwiki.nibib.nih.gov/mediawiki/index.php?title=Multiscale_Systems_Biology_Working_Group

http://www.cnsorg.org/assets/docs/CNS_Workshops/workshop_multiscale.pdf

http://www.incf.org/core/programs/modeling/projects/standards
Multiscale modeling is a tool of critical importance for neuroscience. As computational modeling techniques become integrated with experimental neuroscience, more knowledge can be extracted from existing experimental data. Quantitative models assist in generating experimentally testable hypotheses and in selecting informative experiments. One major challenge in the field is that, because of a wide range of simulation tools being used in the community, it is unlikely that one laboratory can reproduce the results obtained by another group, even if the model is deposited in an openly accessible database. The absence of widely adopted standards for model description also hamper efforts to make existing programs more compatible, reduce opportunities for innovative software development and for benchmarking of existing simulators.

http://www.cccblog.org/2011/04/25/an-interagency-multiscale-modeling-initiative/
Multiscale models can be designed to integrate diverse data, create testable hypotheses leading to new investigational studies, identify and share gaps in knowledge, uncover biological mechanisms, or make predictions about clinical outcome or intervention effects.  These models can draw on a variety of data sources including relevant physical, environmental, clinical and population data. Ultimately multiscale models and the information derived from their use will enable biomedical, biological, behavioral, environmental and clinical researchers to understand complex biological and behavioral systems in a manner not possible through traditional research methodsâ€¦
 
The ultimate goal of the models would be to make realistic scientific predictions to address problems and issues in the environment; in the human body (e.g., to prevent, diagnose and treat the diseases or aberrations in normal development, and/or to predict treatment outcomes); and among individuals, groups, and within populations.

http://www.neuroinformatics2010.org/incf-japan-node-special-symposium/incf-japan-node-session-abstracts
ERIK DE SCHUTTER

New model description standards to facilitate multi-scale modeling

Okinawa Institute of Science and Technology, Japan and University of Antwerp, Belgium

Multi-scale modeling is a tool of critical importance for neuroscience. As computational modeling techniques become integrated with experimental neuroscience, more knowledge can be extracted from existing experimental data. Quantitative models assist in generating experimentally testable hypotheses and in selecting informative experiments. One major challenge in the field is that, because of a wide range of simulation tools being used in the community, it is unlikely that one laboratory can reproduce the results obtained by another group, even if the model is deposited in an openly accessible database. The absence of widely adopted standards for model description also hamper efforts to make existing programs more compatible, reduce opportunities for innovative software development and for benchmarking of existing simulators.
The INCF has started a project to develop a new standard markup language for model description. Based on lessons learned with previous efforts in computational neuroscience and in other fields like systems biology, a concerted effort is made to develop a well-defined but flexible syntax for a self-documenting markup language that will be easy to extend and that can form the basis for specific implementations covering a wide range of modeling scales. The initial effort focuses on describing a growing area of computational neuroscience, spiking networks. This language, called NineML (Network Interchange format for NEuroscience) is based on a layered approach: an abstraction layer allows a full mathematical description of the models, including events and state transitions, while the user layer contains parameter values for specific models. The user layer includes concepts from the four major areas of neuroscience network modeling: neurons, synapses, populations and network connectivity rules. The abstraction layer includes notations for representing hybrid dynamical systems, combining differential equations with event based modeling to describe integrate-and-fire neurons, and abstract ma Cambridge: MA.thematical representations of connectivity rules. These abstractions are capable of describing a vast range of network models from the neuroscience literature.
The first official release of NineML is expected by the end of the year. In a next phase NineML will be improved by incorporating community feedback and by expanding the coverage of different spiking network models. Based on this experience new efforts will be launched in the future, using the same language syntax to cover other areas of computational neuroscience, including compartmental models, synaptic microphysiology, cellular mechanics, electrodynamics. Special attention will be given to interoperability issues relevant to multi-scale modeling, where many separate model descriptions may have to be combined and data interfaces need to be defined.

http://www.frontiersin.org/computational_physiology_and_medicine/10.3389/fphys.2011.00004/abstract


Churchland PS & Sejnowski TJ (1992) The Computational Brain. The MIT Press: Cambridge, MA.

http://books.google.com.au/books?id=wVll6u0tzXoC&printsec=frontcover&source=gbs_ge_summary_r&cad=0#v=onepage&q&f=false

p. 18
Levels in the Nervous System
Marr (1982) articulated a framework for a theory of levels that provided a background for thinking about levels in the context of computation by nervous structures. It drew upon the conception of levels in computer science and resulted in the characterisation of three levels: (1) the computational level of abstract problem analysis , decomposing the task into its main constituents, (2) the algorithmic level, specifying a formal procedure to perform the task so that for a given input, the correct output results, and (3) the level of physical implementation, constructing a working device given a particular technology.
S+C argue that Marr's division really corresponds to three different sorts of questions that can be raised about the phenomenon: (1) How does the problem decompose into parts, (2) what principles govern how the parts interact to solve the problem, and (3) what is the stuff who's causal interactions implement the principles?

Marr considered that a higher-level question was largely independent of the levels below it, thus computational problems of the highest level could be analysed independently of understanding the algorithm which performs the computation. Similarly, the algorithmic problem of the second level was thought to be solvable independently of understanding its physical implementation. Thus, his strategy was top-down rather than bottom-up.
However, two issues were confused in the doctrine of independence. One concerned whether, {\it as a matter of discovery}, the relevant algorithm and problem analysis can be figured out independently of facts about implementation. The other concerns whether, {\it as a matter of formal theory}, a given algorithm which is already known to perform a given task in a given machine (e.g. brain) can be implemented in some other machine which has a different architecture. In the latter case, what computational theory tells us is that an algorithm can be run on different machines, and in that sense, and that sense alone, the algorithm is independent of the implementation. The formal point is straightforward: since an algorithm is formal, no specific physical parameters (e.g. vacuum tubes, Ca^2+) are part of the algorithm.

That said, it is important to see that the purely formal point cannot speak to the issue of how best to discover the algorithm in fact used by a given machine, nor how best to arrive at the neurobiologically adequate task analysis. . . . The formal independence of algorithm from architecture is something we can exploit to build comp[utationally equivalent machines once we know how the brain works, but is no guide to discovery if we do not know how the brain works.

The issues of independence of levels marks a major conceptual difference between Marr (1982) and the current generation of researchers studying neural and connectionist models. In contrast to the doctrine of independence, current research suggests that considerations of implementation play a vital role in the kinds of algorithms that are devised and the kind of computational insights available. Knowledge of brain architecture, far from being irrelevant . . ., can be the essential basis and invaluable catalyst for devising powerful algorithms . . .

Levels of Organization
Marr's three-level divisiontreats each of his levels monolithically as a single level of analysis. However, when measured against levels of organisation in the CNS, the fit is confusing and poor at best. There is organised structure at different scales: molecules, synapses, neurones, networks, layers, maps, and systems. At each structurally specified stratum, we can raise the computational question: What does that organisation of elements do?

missing p. 20-21

Levels of Processing

Lots of pages are missing, but I have a copy somewhere . . 
I will see if I can find it . . .









